{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked with finding the best recommendation based on a given input. We have divided our analyses into two parts:\n",
    "- In the first part, we try to predict the label if only free-form data is given as input. Here, we first pre-processed the data and then tried different models for prediction, then chose the best model for prediction and predicted the type of the outfit. This is to ensure that if free-form data is given to us, we don't end up finding a product with different type\n",
    "- In the second part, we have coded the required results, i.e. outputting based on given input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the outfits data\n",
    "outfits_df = pd.read_csv('outfit_combinations.csv', encoding = 'latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>outfit_item_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Eileen Fisher</td>\n",
       "      <td>Slim Knit Skirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2PEPWFTT7RMP5AA1T</td>\n",
       "      <td>top</td>\n",
       "      <td>Eileen Fisher</td>\n",
       "      <td>Rib Mock Neck Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>accessory1</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DDBHC62ES5K80P0KYJ56AM2T</td>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>shoe</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>Penelope Mid Cap Toe Pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMHCX50CFX5YNG99F3Y65GQW</td>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Eileen Fisher</td>\n",
       "      <td>Slim Knit Skirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    outfit_id                  product_id outfit_item_type  \\\n",
       "0  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2P5H24WK0HTK4R0A1           bottom   \n",
       "1  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2PEPWFTT7RMP5AA1T              top   \n",
       "2  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2S5T9W793F4CY41HE       accessory1   \n",
       "3  01DDBHC62ES5K80P0KYJ56AM2T  01DMBRYVA2ZFDYRYY5TRQZJTBD             shoe   \n",
       "4  01DMHCX50CFX5YNG99F3Y65GQW  01DMBRYVA2P5H24WK0HTK4R0A1           bottom   \n",
       "\n",
       "                 brand               product_full_name  \n",
       "0        Eileen Fisher                 Slim Knit Skirt  \n",
       "1        Eileen Fisher              Rib Mock Neck Tank  \n",
       "2  kate spade new york  medium margaux leather satchel  \n",
       "3           Tory Burch       Penelope Mid Cap Toe Pump  \n",
       "4        Eileen Fisher                 Slim Knit Skirt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the top 5 observations\n",
    "outfits_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bottom', 'top', 'accessory1', 'shoe', 'onepiece', 'accessory2',\n",
       "       'accessory3'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the outfit_item_type unique values\n",
    "outfits_df.outfit_item_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bottom', 'top', 'accessory', 'shoe', 'onepiece'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing accessories label to one label accessory\n",
    "def change_outfit_type(x):\n",
    "    '''\n",
    "    This function converts similar labels into one for style category\n",
    "    '''\n",
    "    x = x.lower()\n",
    "    if x == 'accessory1':\n",
    "        return 'accessory'\n",
    "    if x == 'accessory2':\n",
    "        return 'accessory'\n",
    "    if x == 'accessory3':\n",
    "        return 'accessory'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# keeping values of similar labels into one value\n",
    "outfits_df.outfit_item_type = outfits_df.outfit_item_type.apply(change_outfit_type)\n",
    "\n",
    "# looking at the unique values\n",
    "outfits_df.outfit_item_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outfit_id            0\n",
       "product_id           0\n",
       "outfit_item_type     0\n",
       "brand                0\n",
       "product_full_name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values in the dataframe\n",
    "outfits_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining the unique product IDs in one dataframe\n",
    "prod_IDs = pd.DataFrame(data = list(outfits_df.product_id.unique()), columns = ['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data with description\n",
    "df_all = pd.read_csv(\"Full Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>mpn</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>bc_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DSE9TC2DQXDG6GWKW9NMJ416</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>514683</td>\n",
       "      <td>Ankle-Strap Pump</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:37:15.719107+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>A modern pump, in a rounded silhouette with an...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DSE9SKM19XNA6SJP36JZC065</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>526676</td>\n",
       "      <td>Petite Tie-Neck Top</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2019-11-11 22:36:50.682513+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
       "      <td>Dress it down with jeans and sneakers or dress...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DSJX8GD4DSAP76SPR85HRCMN</td>\n",
       "      <td>Loewe</td>\n",
       "      <td>4.001E+11</td>\n",
       "      <td>52MM Padded Leather Round Sunglasses</td>\n",
       "      <td>Padded leather covers classic round sunglasses.</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval...</td>\n",
       "      <td>2019-11-13 17:33:59.581661+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/loewe-52mm-pad...</td>\n",
       "      <td>100% UV protection\\nCase and cleaning cloth in...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DSJVKJNS6F4KQ1QM6YYK9AW2</td>\n",
       "      <td>Converse</td>\n",
       "      <td>4.00012E+11</td>\n",
       "      <td>Baby's &amp; Little Kid's All-Star Two-Tone Mid-To...</td>\n",
       "      <td>The iconic mid-top design gets an added dose o...</td>\n",
       "      <td>JustKids/Shoes/Baby024Months/BabyGirl,JustKids...</td>\n",
       "      <td>2019-11-13 17:05:05.203733+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/converse-babys...</td>\n",
       "      <td>Canvas upper\\nRound toe\\nLace-up vamp\\nSmartFO...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSK15ZD4D5A0QXA8NSD25YXE</td>\n",
       "      <td>Alexander McQueen</td>\n",
       "      <td>4.00011E+11</td>\n",
       "      <td>64MM Rimless Sunglasses</td>\n",
       "      <td>Hexagonal shades offer a rimless view with int...</td>\n",
       "      <td>JewelryAccessories/SunglassesReaders/RoundOval</td>\n",
       "      <td>2019-11-13 18:42:30.941321+00</td>\n",
       "      <td>2019-12-19 20:40:30.786144+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.saksfifthavenue.com/alexander-mcqu...</td>\n",
       "      <td>100% UV protection\\nGradient lenses\\nAdjustabl...</td>\n",
       "      <td>{\"Needs Review\"}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id              brand          mpn  \\\n",
       "0  01DSE9TC2DQXDG6GWKW9NMJ416    Banana Republic       514683   \n",
       "1  01DSE9SKM19XNA6SJP36JZC065    Banana Republic       526676   \n",
       "2  01DSJX8GD4DSAP76SPR85HRCMN              Loewe    4.001E+11   \n",
       "3  01DSJVKJNS6F4KQ1QM6YYK9AW2           Converse  4.00012E+11   \n",
       "4  01DSK15ZD4D5A0QXA8NSD25YXE  Alexander McQueen  4.00011E+11   \n",
       "\n",
       "                                   product_full_name  \\\n",
       "0                                   Ankle-Strap Pump   \n",
       "1                                Petite Tie-Neck Top   \n",
       "2               52MM Padded Leather Round Sunglasses   \n",
       "3  Baby's & Little Kid's All-Star Two-Tone Mid-To...   \n",
       "4                            64MM Rimless Sunglasses   \n",
       "\n",
       "                                         description  \\\n",
       "0  A modern pump, in a rounded silhouette with an...   \n",
       "1  Dress it down with jeans and sneakers or dress...   \n",
       "2    Padded leather covers classic round sunglasses.   \n",
       "3  The iconic mid-top design gets an added dose o...   \n",
       "4  Hexagonal shades offer a rimless view with int...   \n",
       "\n",
       "                                      brand_category  \\\n",
       "0                                            Unknown   \n",
       "1                                            Unknown   \n",
       "2  JewelryAccessories/SunglassesReaders/RoundOval...   \n",
       "3  JustKids/Shoes/Baby024Months/BabyGirl,JustKids...   \n",
       "4     JewelryAccessories/SunglassesReaders/RoundOval   \n",
       "\n",
       "                      created_at                     updated_at deleted_at  \\\n",
       "0  2019-11-11 22:37:15.719107+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "1  2019-11-11 22:36:50.682513+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "2  2019-11-13 17:33:59.581661+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "3  2019-11-13 17:05:05.203733+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "4  2019-11-13 18:42:30.941321+00  2019-12-19 20:40:30.786144+00        NaN   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://bananarepublic.gap.com/browse/product....   \n",
       "1  https://bananarepublic.gap.com/browse/product....   \n",
       "2  https://www.saksfifthavenue.com/loewe-52mm-pad...   \n",
       "3  https://www.saksfifthavenue.com/converse-babys...   \n",
       "4  https://www.saksfifthavenue.com/alexander-mcqu...   \n",
       "\n",
       "                                             details            labels  \\\n",
       "0  A modern pump, in a rounded silhouette with an...  {\"Needs Review\"}   \n",
       "1  Dress it down with jeans and sneakers or dress...  {\"Needs Review\"}   \n",
       "2  100% UV protection\\nCase and cleaning cloth in...  {\"Needs Review\"}   \n",
       "3  Canvas upper\\nRound toe\\nLace-up vamp\\nSmartFO...  {\"Needs Review\"}   \n",
       "4  100% UV protection\\nGradient lenses\\nAdjustabl...  {\"Needs Review\"}   \n",
       "\n",
       "   bc_product_id  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the top 5 observations\n",
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the columns relevant to the analyses\n",
    "df_all = df_all[['product_id', 'brand', 'product_full_name', 'description', 'brand_category', 'details', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48979, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id              0\n",
       "brand                   0\n",
       "product_full_name       0\n",
       "description          7974\n",
       "brand_category        238\n",
       "details              9866\n",
       "labels                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking NA values\n",
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some rows which do not contain any description or details\n",
    "# replace the null values with\n",
    "df_all=df_all.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41932</th>\n",
       "      <td>01DT51234VHAHGPTR89SZJ50V0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>01DPGTXH6QTM161M660N9W7C3S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>01DPGTXD3HEJ83GAWGBNB0PV92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42074</th>\n",
       "      <td>01DTJCE596G5WGANPMXNENAXFJ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_id  count\n",
       "0      01DMBRYVA2P5H24WK0HTK4R0A1      2\n",
       "41932  01DT51234VHAHGPTR89SZJ50V0      2\n",
       "6064   01DPGTXH6QTM161M660N9W7C3S      2\n",
       "6063   01DPGTXD3HEJ83GAWGBNB0PV92      2\n",
       "42074  01DTJCE596G5WGANPMXNENAXFJ      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate product id entries\n",
    "df_check = df_all.groupby(\"product_id\").size().reset_index(name = 'count').sort_values('count', ascending = False)\n",
    "#len(df_check[df_check['count']>1])\n",
    "df_check.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicate product ids\n",
    "df_all = df_all.drop_duplicates(subset=\"product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48072, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading first file with tags\n",
    "df_tagged = pd.read_excel(\"USC+Product+Attribute+Data+03302020.xlsx\")\n",
    "\n",
    "# loading second file with tags\n",
    "df_tagged2 = pd.read_csv('usc_additional_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining both tag files in one dataframe\n",
    "df_tag = pd.concat([df_tagged, df_tagged2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DVBTBPHR8WJTCVEN5AJRHF47</td>\n",
       "      <td>01DVBTBPJ41VVT00JJCG8TTZ2W</td>\n",
       "      <td>gender</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVA7QRXM928ZM0WWR7HFNTC1</td>\n",
       "      <td>01DVA7QRXXR9F0TWVE1HMC5ZQ3</td>\n",
       "      <td>Primary Color</td>\n",
       "      <td>Blacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>01DPGVGBK6YGNYGNF2S6FSH02T</td>\n",
       "      <td>style</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01E1JM43NQ3H17PB22EV3074NX</td>\n",
       "      <td>01E1JM5WFWWCCCH3JTTTCYQCEQ</td>\n",
       "      <td>style</td>\n",
       "      <td>Modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>01DSE8ZG8Y3FR8KWE2TY1QDWBF</td>\n",
       "      <td>shoe_width</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            product_color_id attribute_name  \\\n",
       "0  01DVBTBPHR8WJTCVEN5AJRHF47  01DVBTBPJ41VVT00JJCG8TTZ2W         gender   \n",
       "1  01DVA7QRXM928ZM0WWR7HFNTC1  01DVA7QRXXR9F0TWVE1HMC5ZQ3  Primary Color   \n",
       "2  01DPGV4YRP3Z8J85DASGZ1Y99W  01DPGVGBK6YGNYGNF2S6FSH02T          style   \n",
       "3  01E1JM43NQ3H17PB22EV3074NX  01E1JM5WFWWCCCH3JTTTCYQCEQ          style   \n",
       "4  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  01DSE8ZG8Y3FR8KWE2TY1QDWBF     shoe_width   \n",
       "\n",
       "  attribute_value  \n",
       "0           Women  \n",
       "1          Blacks  \n",
       "2          Casual  \n",
       "3          Modern  \n",
       "4          Medium  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender', 'Primary Color', 'style', 'shoe_width', 'length_top',\n",
       "       'category', 'fit', 'occasion', 'subcategory_bottom',\n",
       "       'sleeve_length', 'upper_material', 'subcategory_top',\n",
       "       'strap_material', 'Additional Color', 'sizing', 'class_dress',\n",
       "       'Pattern', 'class_pants_and_leggings', 'dry_clean_only',\n",
       "       'length_one_piece', 'material_clothing', 'subcategory_accessory',\n",
       "       'closure_blazers_coats_and_jackets', 'leg_style', 'toe_style',\n",
       "       'neckline', 'class_sandals', 'length_skirts',\n",
       "       'class_jumpsuit_and_romper', 'length_pants_and_leggings',\n",
       "       'subcategory_sweater', 'closure_top',\n",
       "       'class_blazers_coats_and_jackets', 'heel_height', 'class_handbags',\n",
       "       'closure_handbag', 'class_pumps_and_heels', 'sheer',\n",
       "       'class_skirts', 'material_purse', 'embellishment',\n",
       "       'class_mules_and_slides', 'rise', 'subcategory_one_piece',\n",
       "       'subcategory_blazers_coats_and_jackets', 'material',\n",
       "       'subcategory_shoe', 'trend', 'class_flats',\n",
       "       'length_blazers_coats_and_jackets', 'wash', 'heel_shape',\n",
       "       'shaft_height', 'class_boots', 'subcategory_sweatshirt_and_hoodie',\n",
       "       'class_sneakers_and_athletic', 'class_booties', 'strap',\n",
       "       'calf_width', 'class_shorts', 'length_shorts', 'Color',\n",
       "       'class_wedges', 'Print', 'materialclothing', 'primarycolor',\n",
       "       'uppermaterial', 'pattern', 'additionalcolor', 'materialpurse',\n",
       "       'strapmaterial', 'print', 'color', 'beltbucklematerial',\n",
       "       'beltmaterial', 'sunglassframematerial', 'lengthtop',\n",
       "       'subcategorytop', 'sleevelength', 'drycleanonly',\n",
       "       'classsneakersandathletic', 'subcategoryshoe', 'toestyle',\n",
       "       'shoewidth', 'toeexposure', 'closureshoe', 'lengthcoatsandjackets',\n",
       "       'classblazerscoatsandjackets', 'closureblazerscoatsandjackets',\n",
       "       'subcategoryblazerscoatsandjackets', 'classdress',\n",
       "       'lengthonepiece', 'subcategoryonepiece', 'closureonepiece',\n",
       "       'lengthpantsandleggings', 'closurepantsandleggings',\n",
       "       'classpantsandleggings', 'legstyle', 'subcategorybottom',\n",
       "       'lengthblazers', 'lengthskirts', 'classskirts', 'closureskirts',\n",
       "       'closuretop', 'subcategoryaccessory', 'closurehandbag',\n",
       "       'classhandbags', 'subcategorysweater',\n",
       "       'subcategorysweatshirtandhoodie', 'shaftheight', 'calfwidth',\n",
       "       'classboots', 'heelshape', 'heelheight',\n",
       "       'lengthblazerscoatsandjackets', 'classjumpsuitandromper',\n",
       "       'classsandals', 'lengthshorts', 'classshorts', 'risejeans',\n",
       "       'legstylejeans', 'lengthjeans', 'closureshorts',\n",
       "       'classmulesandslides', 'classbooties', 'classpumpsandheels',\n",
       "       'closuresweater', 'classflats', 'classsunglasses',\n",
       "       'beltbuckleshape', 'beltclosure', 'classbelts',\n",
       "       'sweatshirtandhoodieclosure', 'classwedges', 'classslippers',\n",
       "       'beltwidth'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag.attribute_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We manually searched for categories which are most relevant for our analyses\n",
    "final_cat = ['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37292872/how-can-i-one-hot-encode-in-python\n",
    "# we then one hot encoded these categories so that we can keep the ones required\n",
    "one_hot = pd.get_dummies(df_tag['attribute_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keeping the required category\n",
    "one_hot = one_hot[final_cat]\n",
    "one_hot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to store the one hot encoded values\n",
    "df_tag_keep = df_tag.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_color_id</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DVBTBPHR8WJTCVEN5AJRHF47</td>\n",
       "      <td>01DVBTBPJ41VVT00JJCG8TTZ2W</td>\n",
       "      <td>gender</td>\n",
       "      <td>Women</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DVA7QRXM928ZM0WWR7HFNTC1</td>\n",
       "      <td>01DVA7QRXXR9F0TWVE1HMC5ZQ3</td>\n",
       "      <td>Primary Color</td>\n",
       "      <td>Blacks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
       "      <td>01DPGVGBK6YGNYGNF2S6FSH02T</td>\n",
       "      <td>style</td>\n",
       "      <td>Casual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01E1JM43NQ3H17PB22EV3074NX</td>\n",
       "      <td>01E1JM5WFWWCCCH3JTTTCYQCEQ</td>\n",
       "      <td>style</td>\n",
       "      <td>Modern</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DSE8Z2ZDAZKZ2SKCS1E3B3HK</td>\n",
       "      <td>01DSE8ZG8Y3FR8KWE2TY1QDWBF</td>\n",
       "      <td>shoe_width</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id            product_color_id attribute_name  \\\n",
       "0  01DVBTBPHR8WJTCVEN5AJRHF47  01DVBTBPJ41VVT00JJCG8TTZ2W         gender   \n",
       "1  01DVA7QRXM928ZM0WWR7HFNTC1  01DVA7QRXXR9F0TWVE1HMC5ZQ3  Primary Color   \n",
       "2  01DPGV4YRP3Z8J85DASGZ1Y99W  01DPGVGBK6YGNYGNF2S6FSH02T          style   \n",
       "3  01E1JM43NQ3H17PB22EV3074NX  01E1JM5WFWWCCCH3JTTTCYQCEQ          style   \n",
       "4  01DSE8Z2ZDAZKZ2SKCS1E3B3HK  01DSE8ZG8Y3FR8KWE2TY1QDWBF     shoe_width   \n",
       "\n",
       "  attribute_value  category  \n",
       "0           Women         0  \n",
       "1          Blacks         0  \n",
       "2          Casual         0  \n",
       "3          Modern         0  \n",
       "4          Medium         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the one hot encoded values with the dataframe containing values of product id\n",
    "df_tag_keep = pd.concat([df_tag_keep, one_hot], axis=1)\n",
    "df_tag_keep.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the rows with style labels\n",
    "df_cat_temp = df_tag_keep[df_tag_keep['category']>0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accessory', 'Top', 'Bottom', 'Shoe', 'Blazers, Coats & Jackets',\n",
       "       'Sweater', 'One Piece', 'Sweatshirt & Hoodie', 'top', 'shoe',\n",
       "       'blazerscoatsjackets', 'onepiece', 'bottom', 'accessory',\n",
       "       'sweater', 'sweatshirthoodie'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observing the values of label for the category\n",
    "df_cat_temp.attribute_value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accessory', 'top', 'bottom', 'shoe', 'blazers, coats & jackets',\n",
       "       'sweater', 'one piece', 'sweatshirt & hoodie',\n",
       "       'blazerscoatsjackets', 'sweatshirthoodie'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the labels into one similar label\n",
    "def change_label_cat(x):\n",
    "    '''\n",
    "    This function converts similar labels into one for cat category\n",
    "    '''\n",
    "    x = x.lower()\n",
    "    if x == 'onepiece':\n",
    "        return 'one piece'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# keeping values of similar labels into one value\n",
    "df_cat_temp.attribute_value = df_cat_temp.attribute_value.apply(change_label_cat)\n",
    "\n",
    "# looking at the unique values\n",
    "df_cat_temp.attribute_value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then one hot encode the labels for each row\n",
    "df_cat_temp = df_cat_temp[['product_id', 'attribute_name', 'attribute_value']]\n",
    "\n",
    "# Remove duplicates\n",
    "df_cat_temp = df_cat_temp.drop_duplicates(subset = ['product_id', 'attribute_name', 'attribute_value'], keep='first')\n",
    "\n",
    "# one hot encoding\n",
    "one_hot_cat = pd.get_dummies(df_cat_temp['attribute_value'])\n",
    "\n",
    "# combining in one dataframe\n",
    "df_cat_temp = pd.concat([df_cat_temp, one_hot_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform operations to ensure there is only one row for one product id\n",
    "# sum the rows to get one value per label per row\n",
    "df_cat_sum = df_cat_temp.groupby('product_id').sum().reset_index()\n",
    "\n",
    "# get all the values of label in one cell for each row\n",
    "df_cat_concat = df_cat_temp.groupby(['product_id', 'attribute_name'])['attribute_value'].apply(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>accessory</th>\n",
       "      <th>bottom</th>\n",
       "      <th>one piece</th>\n",
       "      <th>top</th>\n",
       "      <th>shoe</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DMBRYVA2Q2ST7MNYR6EEY4TK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01DMHCNT41E14QWP503V7CT9G6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  accessory  bottom  one piece  top  shoe  \\\n",
       "0  01DMBRYVA2P5H24WK0HTK4R0A1          0       1          0    0     0   \n",
       "2  01DMBRYVA2Q2ST7MNYR6EEY4TK          0       0          1    0     0   \n",
       "3  01DMBRYVA2S5T9W793F4CY41HE          1       0          0    0     0   \n",
       "4  01DMBRYVA2ZFDYRYY5TRQZJTBD          0       0          0    0     1   \n",
       "5  01DMHCNT41E14QWP503V7CT9G6          1       0          0    0     0   \n",
       "\n",
       "  attribute_value  \n",
       "0          bottom  \n",
       "2       one piece  \n",
       "3       accessory  \n",
       "4            shoe  \n",
       "5       accessory  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the final dataframe\n",
    "\n",
    "# retaining the rows with the five labels we are interested in (shoe, accessory, bottom, one piece, top)\n",
    "df_cat = pd.merge(df_cat_sum, df_cat_concat[['product_id', 'attribute_value']], on = 'product_id')\n",
    "df_cat = df_cat[['product_id', 'accessory', 'bottom', 'one piece', 'top', 'shoe', 'attribute_value']]\n",
    "df_cat = df_cat[(df_cat['accessory']>0)|(df_cat['bottom']>0)|(df_cat['top']>0)|(df_cat['one piece']>0)|(df_cat['shoe']>0)]\n",
    "df_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id         0\n",
       "accessory          0\n",
       "bottom             0\n",
       "one piece          0\n",
       "top                0\n",
       "shoe               0\n",
       "attribute_value    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check if there is any row with na value after the operations\n",
    "df_cat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the final dataframe for the category with text details from the dataframe containint all information\n",
    "df_cat = pd.merge(df_cat, df_all, on = 'product_id', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accessory    1\n",
       "bottom       1\n",
       "one piece    1\n",
       "top          1\n",
       "shoe         1\n",
       "dtype: uint8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are values of label more than 1\n",
    "# since we are doing binary classification for each label, we would like to keep the values as 0 or 1\n",
    "df_cat[['accessory', 'bottom', 'one piece', 'top', 'shoe']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>accessory</th>\n",
       "      <th>bottom</th>\n",
       "      <th>one piece</th>\n",
       "      <th>top</th>\n",
       "      <th>shoe</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom</td>\n",
       "      <td>Eileen Fisher</td>\n",
       "      <td>Slim Knit Skirt</td>\n",
       "      <td>A nice skirt</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>{\"Needs Attributes\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DMBRYVA2Q2ST7MNYR6EEY4TK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one piece</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>Chemelle Midi Dress</td>\n",
       "      <td>A nice dress</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "      <td>A nice bag</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shoe</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>Penelope Mid Cap Toe Pump</td>\n",
       "      <td>A nice shoe</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMHCNT41E14QWP503V7CT9G6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>Nina</td>\n",
       "      <td>Crystal Clutch</td>\n",
       "      <td>A nice clutch</td>\n",
       "      <td>Accessory</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  accessory  bottom  one piece  top  shoe  \\\n",
       "0  01DMBRYVA2P5H24WK0HTK4R0A1          0       1          0    0     0   \n",
       "1  01DMBRYVA2Q2ST7MNYR6EEY4TK          0       0          1    0     0   \n",
       "2  01DMBRYVA2S5T9W793F4CY41HE          1       0          0    0     0   \n",
       "3  01DMBRYVA2ZFDYRYY5TRQZJTBD          0       0          0    0     1   \n",
       "4  01DMHCNT41E14QWP503V7CT9G6          1       0          0    0     0   \n",
       "\n",
       "  attribute_value                brand               product_full_name  \\\n",
       "0          bottom        Eileen Fisher                 Slim Knit Skirt   \n",
       "1       one piece            Equipment             Chemelle Midi Dress   \n",
       "2       accessory  kate spade new york  medium margaux leather satchel   \n",
       "3            shoe           Tory Burch       Penelope Mid Cap Toe Pump   \n",
       "4       accessory                 Nina                  Crystal Clutch   \n",
       "\n",
       "     description brand_category  details                           labels  \n",
       "0   A nice skirt        Apparel  Unknown             {\"Needs Attributes\"}  \n",
       "1   A nice dress        Apparel  Unknown  [{'value': 'Needs Attributes'}]  \n",
       "2     A nice bag           Bags  Unknown  [{'value': 'Needs Attributes'}]  \n",
       "3    A nice shoe          Shoes  Unknown                               []  \n",
       "4  A nice clutch      Accessory  Unknown                               []  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the first 5 observations\n",
    "df_cat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a copy of the original dataframe in case of refresh is required\n",
    "df_pre = df_cat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we pre-processed the data, regex cleaning, stop words removal and lemmatization before we use the data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "#!pip install unidecode\n",
    "#https://stackoverflow.com/questions/44431730/how-to-replace-accented-characters-in-python\n",
    "    \n",
    "def clean_punct(review_to_be_cleaned):\n",
    "    '''\n",
    "    Function which takes a list of sentences and cleans the data. Returns a cleaned list of sentences\n",
    "    '''\n",
    "    temp = review_to_be_cleaned\n",
    "\n",
    "    #Normalize tabs and remove newlines\n",
    "    temp = temp.replace('\\t', ' ').replace('\\n', ' ')\n",
    "    \n",
    "    # replacing the accented characters\n",
    "    #temp = unicode(temp, \"utf-8\")\n",
    "    temp = unidecode.unidecode(temp)\n",
    "    \n",
    "    # Replace punctuation with whitespace\n",
    "    punc_syn = string.punctuation\n",
    "    punc_syn = punc_syn.replace('\"','')\n",
    "    punc_syn = punc_syn.replace('-','')\n",
    "    temp = re.sub(r'[{}]'.format(punc_syn), ' ', temp)\n",
    "    \n",
    "    # Single character removal \n",
    "    temp = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', temp)\n",
    "    \n",
    "    #Remove leading whitespaces\n",
    "    temp = temp.strip()\n",
    "\n",
    "    #Normalize spaces to 1\n",
    "    temp = re.sub(\" +\", \" \", temp)\n",
    "\n",
    "    #Normalize all characters to lowercase\n",
    "    temp = temp.lower()\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the required columns\n",
    "list_cols = ['brand', 'product_full_name', 'description', 'brand_category', 'details']\n",
    "\n",
    "for i in list_cols:\n",
    "    df_pre[i] = df_pre[i].astype(str).apply(clean_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>accessory</th>\n",
       "      <th>bottom</th>\n",
       "      <th>one piece</th>\n",
       "      <th>top</th>\n",
       "      <th>shoe</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>a nice skirt</td>\n",
       "      <td>apparel</td>\n",
       "      <td>unknown</td>\n",
       "      <td>{\"Needs Attributes\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DMBRYVA2Q2ST7MNYR6EEY4TK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one piece</td>\n",
       "      <td>equipment</td>\n",
       "      <td>chemelle midi dress</td>\n",
       "      <td>a nice dress</td>\n",
       "      <td>apparel</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "      <td>a nice bag</td>\n",
       "      <td>bags</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tory burch</td>\n",
       "      <td>penelope mid cap toe pump</td>\n",
       "      <td>a nice shoe</td>\n",
       "      <td>shoes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMHCNT41E14QWP503V7CT9G6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>nina</td>\n",
       "      <td>crystal clutch</td>\n",
       "      <td>a nice clutch</td>\n",
       "      <td>accessory</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  accessory  bottom  one piece  top  shoe  \\\n",
       "0  01DMBRYVA2P5H24WK0HTK4R0A1          0       1          0    0     0   \n",
       "1  01DMBRYVA2Q2ST7MNYR6EEY4TK          0       0          1    0     0   \n",
       "2  01DMBRYVA2S5T9W793F4CY41HE          1       0          0    0     0   \n",
       "3  01DMBRYVA2ZFDYRYY5TRQZJTBD          0       0          0    0     1   \n",
       "4  01DMHCNT41E14QWP503V7CT9G6          1       0          0    0     0   \n",
       "\n",
       "  attribute_value                brand               product_full_name  \\\n",
       "0          bottom        eileen fisher                 slim knit skirt   \n",
       "1       one piece            equipment             chemelle midi dress   \n",
       "2       accessory  kate spade new york  medium margaux leather satchel   \n",
       "3            shoe           tory burch       penelope mid cap toe pump   \n",
       "4       accessory                 nina                  crystal clutch   \n",
       "\n",
       "     description brand_category  details                           labels  \n",
       "0   a nice skirt        apparel  unknown             {\"Needs Attributes\"}  \n",
       "1   a nice dress        apparel  unknown  [{'value': 'Needs Attributes'}]  \n",
       "2     a nice bag           bags  unknown  [{'value': 'Needs Attributes'}]  \n",
       "3    a nice shoe          shoes  unknown                               []  \n",
       "4  a nice clutch      accessory  unknown                               []  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the first 5 observations\n",
    "df_pre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:30<00:00, 18.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# using spacy library to remove the stop words\n",
    "for i in tqdm(list_cols):\n",
    "    df_pre[i] = list(\n",
    "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), list(df_pre[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Using nltk library to perform lemmatization\n",
    "def lemm(list_to_process):\n",
    "    '''\n",
    "    This function returns the list of reviews after lemmatization\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentences = []\n",
    "    \n",
    "    for i in list_to_process:\n",
    "        tokens = nltk.word_tokenize(i)\n",
    "        words = []\n",
    "        for word in tokens:\n",
    "            words.append(lemmatizer.lemmatize(word))\n",
    "        sentence = \" \".join(words)\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing lemmatization on the required columns\n",
    "for i in list_cols:\n",
    "    df_pre[i] = lemm(df_pre[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all text in one column\n",
    "df_pre['combined'] =  df_pre.brand+' '+df_pre.product_full_name+' '+df_pre.description+' '+df_pre.brand_category+' '+df_pre.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>accessory</th>\n",
       "      <th>bottom</th>\n",
       "      <th>one piece</th>\n",
       "      <th>top</th>\n",
       "      <th>shoe</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>details</th>\n",
       "      <th>labels</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DMBRYVA2P5H24WK0HTK4R0A1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bottom</td>\n",
       "      <td>eileen fisher</td>\n",
       "      <td>slim knit skirt</td>\n",
       "      <td>nice skirt</td>\n",
       "      <td>apparel</td>\n",
       "      <td>unknown</td>\n",
       "      <td>{\"Needs Attributes\"}</td>\n",
       "      <td>eileen fisher slim knit skirt nice skirt appar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DMBRYVA2Q2ST7MNYR6EEY4TK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one piece</td>\n",
       "      <td>equipment</td>\n",
       "      <td>chemelle midi dress</td>\n",
       "      <td>nice dress</td>\n",
       "      <td>apparel</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "      <td>equipment chemelle midi dress nice dress appar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DMBRYVA2S5T9W793F4CY41HE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>kate spade new york</td>\n",
       "      <td>medium margaux leather satchel</td>\n",
       "      <td>nice bag</td>\n",
       "      <td>bag</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[{'value': 'Needs Attributes'}]</td>\n",
       "      <td>kate spade new york medium margaux leather sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DMBRYVA2ZFDYRYY5TRQZJTBD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tory burch</td>\n",
       "      <td>penelope mid cap toe pump</td>\n",
       "      <td>nice shoe</td>\n",
       "      <td>shoe</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>tory burch penelope mid cap toe pump nice shoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DMHCNT41E14QWP503V7CT9G6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accessory</td>\n",
       "      <td>nina</td>\n",
       "      <td>crystal clutch</td>\n",
       "      <td>nice clutch</td>\n",
       "      <td>accessory</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[]</td>\n",
       "      <td>nina crystal clutch nice clutch accessory unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  accessory  bottom  one piece  top  shoe  \\\n",
       "0  01DMBRYVA2P5H24WK0HTK4R0A1          0       1          0    0     0   \n",
       "1  01DMBRYVA2Q2ST7MNYR6EEY4TK          0       0          1    0     0   \n",
       "2  01DMBRYVA2S5T9W793F4CY41HE          1       0          0    0     0   \n",
       "3  01DMBRYVA2ZFDYRYY5TRQZJTBD          0       0          0    0     1   \n",
       "4  01DMHCNT41E14QWP503V7CT9G6          1       0          0    0     0   \n",
       "\n",
       "  attribute_value                brand               product_full_name  \\\n",
       "0          bottom        eileen fisher                 slim knit skirt   \n",
       "1       one piece            equipment             chemelle midi dress   \n",
       "2       accessory  kate spade new york  medium margaux leather satchel   \n",
       "3            shoe           tory burch       penelope mid cap toe pump   \n",
       "4       accessory                 nina                  crystal clutch   \n",
       "\n",
       "   description brand_category  details                           labels  \\\n",
       "0   nice skirt        apparel  unknown             {\"Needs Attributes\"}   \n",
       "1   nice dress        apparel  unknown  [{'value': 'Needs Attributes'}]   \n",
       "2     nice bag            bag  unknown  [{'value': 'Needs Attributes'}]   \n",
       "3    nice shoe           shoe  unknown                               []   \n",
       "4  nice clutch      accessory  unknown                               []   \n",
       "\n",
       "                                            combined  \n",
       "0  eileen fisher slim knit skirt nice skirt appar...  \n",
       "1  equipment chemelle midi dress nice dress appar...  \n",
       "2  kate spade new york medium margaux leather sat...  \n",
       "3  tory burch penelope mid cap toe pump nice shoe...  \n",
       "4  nina crystal clutch nice clutch accessory unknown  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining the required columns\n",
    "df_pre = df_pre[['product_id', 'accessory', 'bottom', 'one piece', 'top', 'shoe', 'attribute_value', 'combined']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe into a new dataframe\n",
    "df_category = df_pre.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe in a csv file\n",
    "df_category.to_csv('01 category.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we define several vectorizer methods and models. We divide the current data into training and test data set in the proportion of 0.75-0.25. We evaluate our models on the test data with 50% accuracy as the baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using count vectorization, tfidf vectorization with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_(docs):\n",
    "    '''\n",
    "    This returns count vectorized vectors of the docs using unigrams\n",
    "    '''\n",
    "    \n",
    "    # use English stopwords, and use one-hot encoding, and the word must appear in at least two of the movie plots\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,1), stop_words=\"english\", binary=True, min_df=10, max_df=5000) \n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "\n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer\n",
    "\n",
    "def count_2gram(docs):\n",
    "    '''\n",
    "    This returns count vectorized vectors of the docs using bigrams\n",
    "    '''\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,2), stop_words=\"english\", binary=True, min_df=10, max_df=5000)\n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "\n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer\n",
    "\n",
    "def count_3gram(docs):\n",
    "    '''\n",
    "    This returns count vectorized vectors of the docs using trigrams\n",
    "    '''\n",
    "    vectorizer = CountVectorizer(ngram_range=(3,3), stop_words=\"english\", binary=True, min_df=10, max_df=5000)\n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "    \n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer\n",
    "\n",
    "def tfidf(docs):\n",
    "    '''\n",
    "    This returns tfidf vectorized vectors of the docs using unigrams\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=\"english\", max_df=0.75)\n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "\n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer\n",
    "\n",
    "def tfidf_2gram(docs):\n",
    "    '''\n",
    "    This returns tfidf vectorized vectors of the docs using bigrams\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2,2), stop_words=\"english\", max_df=0.75)\n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "\n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer\n",
    "\n",
    "def tfidf_3gram(docs):\n",
    "    '''\n",
    "    This returns tfidf vectorized vectors of the docs using trigrams\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(3,3), stop_words=\"english\", max_df=0.75)\n",
    "    vectorizer = vectorizer.fit(docs)\n",
    "    X = vectorizer.transform(docs)\n",
    "\n",
    "    vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    return vectorized_df, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def log_reg(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    This function returns the accuracy of the model with the given inputs\n",
    "    '''\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    return round(np.mean(y_pred == Y_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaa99e6f698450895770a7c3837b900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating list to store values of different parameters\n",
    "category_list = []\n",
    "label_list = []\n",
    "vectorizer_list = []\n",
    "logreg_accuracy = []\n",
    "\n",
    "i = 'category'\n",
    "df = df_category.copy()\n",
    "\n",
    "# getting the labels for each category   \n",
    "labels = list(df.iloc[:,1:-2].columns)\n",
    "\n",
    "for j in tqdm_notebook(labels):\n",
    "\n",
    "    # looping through each vectorization methods defined above in the functions\n",
    "    for k in ['c_1ng', 'c_2ng', 'c_3ng', 'tfidf_1ng', 'tfidf_2ng', 'tfidf_3ng']:\n",
    "\n",
    "        # storing values of category and labels\n",
    "        category_list.append(i)\n",
    "        label_list.append(j)\n",
    "\n",
    "        # splitting the data into training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df['combined'], df[j], test_size=0.25, random_state=42)\n",
    "\n",
    "        # for each vectorization method, get the vectorized training data and the vectorizer\n",
    "        if k==\"c_1ng\":\n",
    "            train_df, vectorizer = count_(X_train)\n",
    "            vectorizer_list.append(\"count_1gram\")\n",
    "\n",
    "        if k==\"c_2ng\":\n",
    "            train_df, vectorizer = count_2gram(X_train)\n",
    "            vectorizer_list.append(\"count_2gram\")\n",
    "\n",
    "        if k==\"c_3ng\":\n",
    "            train_df, vectorizer = count_3gram(X_train)\n",
    "            vectorizer_list.append(\"count_3gram\")\n",
    "\n",
    "        if k==\"tfidf_1ng\":\n",
    "            train_df, vectorizer = tfidf(X_train)\n",
    "            vectorizer_list.append(\"tfid_1gram\")\n",
    "\n",
    "        if k==\"tfidf_2ng\":\n",
    "            train_df, vectorizer = tfidf_2gram(X_train)\n",
    "            vectorizer_list.append(\"tfidf_2gram\")\n",
    "\n",
    "        if k==\"tfidf_3ng\":\n",
    "            train_df, vectorizer = tfidf_3gram(X_train)\n",
    "            vectorizer_list.append(\"tfidf_3gram\")\n",
    "\n",
    "        # converting the test data into vector using the vectorizer obtained above\n",
    "        test_vector = vectorizer.transform(X_test)\n",
    "        test_df = pd.DataFrame(test_vector.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "        # getting the accuracy of the model and storing in a list\n",
    "        accuracy = log_reg(train_df, y_train, test_df, y_test)\n",
    "        logreg_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the performance of each approach in a dataframe\n",
    "results_logreg = pd.DataFrame({\"category\":category_list, \"label\":label_list, \"vectorizer\":vectorizer_list,\n",
    "                               \"LogReg_Accuracy\":logreg_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>LogReg_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>count_2gram</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>count_3gram</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>tfid_1gram</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>tfidf_2gram</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>tfidf_3gram</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>count_2gram</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>count_3gram</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>tfid_1gram</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label   vectorizer  LogReg_Accuracy\n",
       "0  category  accessory  count_1gram             1.00\n",
       "1  category  accessory  count_2gram             0.98\n",
       "2  category  accessory  count_3gram             0.96\n",
       "3  category  accessory   tfid_1gram             0.98\n",
       "4  category  accessory  tfidf_2gram             0.95\n",
       "5  category  accessory  tfidf_3gram             0.93\n",
       "6  category     bottom  count_1gram             0.99\n",
       "7  category     bottom  count_2gram             0.96\n",
       "8  category     bottom  count_3gram             0.89\n",
       "9  category     bottom   tfid_1gram             0.98"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at 10 observations\n",
    "results_logreg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results in a file\n",
    "results_logreg.to_csv('01 Results_logreg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>LogReg_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tfid_1gram</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label   vectorizer  LogReg_Accuracy\n",
       "4  category        top  count_1gram             0.98\n",
       "1  category       shoe   tfid_1gram             1.00\n",
       "2  category  one piece  count_1gram             0.99\n",
       "3  category     bottom  count_1gram             0.99\n",
       "0  category  accessory  count_1gram             1.00"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing basic operations to get the model with the highest accuracy\n",
    "\n",
    "results_logreg = results_logreg.sort_values('LogReg_Accuracy', ascending=False).drop_duplicates(['category','label'])\n",
    "results_logreg = results_logreg.reset_index()\n",
    "results_logreg = results_logreg.drop(columns = ['index'])\n",
    "results_logreg = results_logreg.sort_values(['category', 'label'], ascending=False)\n",
    "results_logreg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Word Embeddings with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Masking\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    '''\n",
    "    This function returns the maximum length of a document within a corpus\n",
    "    '''\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    '''\n",
    "    This function returns the integer encodings of the docs with the given tokenizer (keras here)\n",
    "    '''\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_m(X_train, y_train, X_test, y_test, vocab_size, EMBEDDING_SIZE, max_length):\n",
    "    '''\n",
    "    This function returns accuracy of the keras model with the given parameters\n",
    "    '''\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # since we are doing binary classification, activation function is sigmoid\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    # compiling the model, fitting on training data and returning accuracy\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52e50818c7149329459b0bd9c0d60cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating list to store values of different parameters\n",
    "category_list = []\n",
    "label_list = []\n",
    "vectorizer_list = []\n",
    "keras_accuracy = []\n",
    "\n",
    "i = 'category'\n",
    "df = df_category.copy()\n",
    "# getting the labels for each category\n",
    "labels = list(df.iloc[:,1:-2].columns)\n",
    "\n",
    "for j in tqdm_notebook(labels):\n",
    "\n",
    "    # getting the word embeddings of the corpus\n",
    "\n",
    "    # Using keras tokenizer and fitting on the category corpus\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(df['combined'])\n",
    "\n",
    "    # getting the maximum length of the docs within the corpus\n",
    "    max_length = get_max_token_length_per_doc(df['combined'])\n",
    "\n",
    "    # integer encode the training data\n",
    "    encoded_docs = integer_encode_documents(df['combined'], tokenizer)\n",
    "    # pad the documents\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # get vocab size\n",
    "    vocab_size = int(len(tokenizer.word_index) + 1)\n",
    "\n",
    "    # splitting data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(padded_docs, df[j], test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "    EMBEDDING_SIZE = 50\n",
    "\n",
    "    # getting the accuracy of keras model with word embeddings\n",
    "    accuracy = keras_m(X_train, y_train, X_test, y_test, vocab_size, EMBEDDING_SIZE, max_length)\n",
    "\n",
    "    # Storing values in a list\n",
    "    keras_accuracy.append(accuracy)\n",
    "    category_list.append(i)\n",
    "    label_list.append(j)\n",
    "    vectorizer_list.append(\"keras-word embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing results in a dataframe\n",
    "results_keras_w = pd.DataFrame({\"category\":category_list, \"label\":label_list, \"vectorizer\":vectorizer_list,\n",
    "                               \"Keras_Accuracy\":keras_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>Keras_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label        vectorizer  Keras_Accuracy\n",
       "0  category  accessory  keras-word embed            1.00\n",
       "1  category     bottom  keras-word embed            1.00\n",
       "2  category  one piece  keras-word embed            0.99\n",
       "3  category        top  keras-word embed            0.99\n",
       "4  category       shoe  keras-word embed            1.00"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 observations\n",
    "results_keras_w.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing in a csv file\n",
    "results_keras_w.to_csv('01 Results_keras_w.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pre_Trained Embeddings with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, argmax, asarray, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the embedings\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_gl(X_train, y_train, X_test, y_test, vocab_size, embedding_matrix, max_length, padded_docs):\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    model.add(e)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "    \n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # return accuracy of the model\n",
    "    return round(accuracy,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f37bd139ff3495ca542efe55b20290e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# list to contain various values of the parameters\n",
    "category_list = []\n",
    "label_list = []\n",
    "vectorizer_list = []\n",
    "keras_glove_accuracy = []\n",
    "\n",
    "i = 'category'\n",
    "df = df_category.copy()\n",
    "# getting labels for each category\n",
    "labels = list(df.iloc[:,1:-2].columns)\n",
    "\n",
    "for j in tqdm_notebook(labels):\n",
    "\n",
    "    # getting the word embedings\n",
    "    # similar to what we did before\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "    tokenizer.fit_on_texts(df['combined'])\n",
    "\n",
    "    max_length = get_max_token_length_per_doc(df['combined'])\n",
    "\n",
    "    # integer encode the training data\n",
    "    encoded_docs = integer_encode_documents(df['combined'], tokenizer)\n",
    "    # pad the documents\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    # get vocab size\n",
    "    vocab_size = int(len(tokenizer.word_index) + 1)\n",
    "\n",
    "    # create a weight matrix for words in training docs\n",
    "    embedding_matrix = zeros((vocab_size, 100))\n",
    "    for word, p in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "            embedding_matrix[p] = embedding_vector\n",
    "\n",
    "    # splitting into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(padded_docs, df[j], test_size=0.25, random_state=42)\n",
    "\n",
    "    # fixed size for glove approach\n",
    "    EMBEDDING_SIZE = 100\n",
    "\n",
    "    accuracy = keras_gl(X_train, y_train, X_test, y_test, vocab_size, embedding_matrix, max_length, padded_docs)\n",
    "\n",
    "    # Storing values in a list\n",
    "    keras_glove_accuracy.append(accuracy)\n",
    "    category_list.append(i)\n",
    "    label_list.append(j)\n",
    "    vectorizer_list.append(\"keras-glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing values in a dataframe\n",
    "results_keras_gl = pd.DataFrame({\"category\":category_list, \"label\":label_list, \"vectorizer\":vectorizer_list,\n",
    "                               \"KerasGlove_Accuracy\":keras_glove_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>KerasGlove_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label   vectorizer  KerasGlove_Accuracy\n",
       "0  category  accessory  keras-glove                 0.98\n",
       "1  category     bottom  keras-glove                 0.94\n",
       "2  category  one piece  keras-glove                 0.93\n",
       "3  category        top  keras-glove                 0.89\n",
       "4  category       shoe  keras-glove                 0.99"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 observations\n",
    "results_keras_gl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing results in a file\n",
    "results_keras_gl.to_csv('04 Results_keras_gl.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best model for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.98</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>tfid_1gram</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.99</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>0.99</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>count_1gram</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label   vectorizer  Accuracy   model\n",
       "4  category        top  count_1gram      0.98  LogReg\n",
       "1  category       shoe   tfid_1gram      1.00  LogReg\n",
       "2  category  one piece  count_1gram      0.99  LogReg\n",
       "3  category     bottom  count_1gram      0.99  LogReg\n",
       "0  category  accessory  count_1gram      1.00  LogReg"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing basic operations to combine all the results\n",
    "results_logreg['model'] = 'LogReg'\n",
    "results_logreg = results_logreg.rename(columns={'LogReg_Accuracy':'Accuracy'})\n",
    "\n",
    "results_logreg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.98</td>\n",
       "      <td>Keras-Glove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.94</td>\n",
       "      <td>Keras-Glove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.93</td>\n",
       "      <td>Keras-Glove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Keras-Glove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>keras-glove</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Keras-Glove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label   vectorizer  Accuracy        model\n",
       "0  category  accessory  keras-glove      0.98  Keras-Glove\n",
       "1  category     bottom  keras-glove      0.94  Keras-Glove\n",
       "2  category  one piece  keras-glove      0.93  Keras-Glove\n",
       "3  category        top  keras-glove      0.89  Keras-Glove\n",
       "4  category       shoe  keras-glove      0.99  Keras-Glove"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing basic operations to combine all the results\n",
    "results_keras_gl['model'] = 'Keras-Glove'\n",
    "results_keras_gl = results_keras_gl.rename(columns={'KerasGlove_Accuracy':'Accuracy'})\n",
    "\n",
    "results_keras_gl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that keras-glove approach didn't give higher accuracies, hence we retained count-tfidf approach here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Keras-Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Keras-Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Keras-Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Keras-Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>keras-word embed</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Keras-Word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label        vectorizer  Accuracy       model\n",
       "0  category  accessory  keras-word embed      1.00  Keras-Word\n",
       "1  category     bottom  keras-word embed      1.00  Keras-Word\n",
       "2  category  one piece  keras-word embed      0.99  Keras-Word\n",
       "3  category        top  keras-word embed      0.99  Keras-Word\n",
       "4  category       shoe  keras-word embed      1.00  Keras-Word"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing basic operations to combine all the results\n",
    "results_keras_w['model'] = 'Keras-Word'\n",
    "results_keras_w = results_keras_w.rename(columns={'Keras_Accuracy':'Accuracy'})\n",
    "\n",
    "results_keras_w.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that word embeding with keras gave us the best accuracies on the test set, hence we moved ahead with using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fin = results_keras_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing value in a csv file\n",
    "results_fin.to_csv('01 Final Results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_m_fin(X_train, y_train, vocab_size, EMBEDDING_SIZE, max_length):\n",
    "    '''\n",
    "    returns the neural network model by fitting on the given data using the given parameters\n",
    "    '''\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=max_length))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # since we are doing binary classification, activation function is sigmoid\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    \n",
    "    # compiling and fiting the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38e17aa4c5e4c21a053bed4e8c77e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating lists to store values\n",
    "category_list = []\n",
    "label_list = []\n",
    "models_list = []\n",
    "\n",
    "i = 'category'\n",
    "df = df_category.copy()\n",
    "        \n",
    "# getting all the labels for the category\n",
    "labels = list(df.iloc[:,1:-2].columns)\n",
    "\n",
    "# keras tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(df['combined'])\n",
    "\n",
    "# maximmum length of a document within the corpus\n",
    "max_length = get_max_token_length_per_doc(df['combined'])\n",
    "\n",
    "# integer encode the training data\n",
    "encoded_docs = integer_encode_documents(df['combined'], tokenizer)\n",
    "# pad the documents\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "# get vocab size\n",
    "vocab_size = int(len(tokenizer.word_index) + 1)\n",
    "\n",
    "for j in tqdm_notebook(labels):\n",
    "\n",
    "    # run for each label\n",
    "    # storing the values of category and label\n",
    "    category_list.append(i)\n",
    "    label_list.append(j)\n",
    "\n",
    "    # using the whole corpus as the training data\n",
    "    X_train = df['combined'].copy()\n",
    "    y_train = df[j].copy()\n",
    "\n",
    "    EMBEDDING_SIZE = 50\n",
    "    model = keras_m_fin(padded_docs, y_train, vocab_size, EMBEDDING_SIZE, max_length)\n",
    "    models_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing values in a dataframe\n",
    "mod_vec = pd.DataFrame({\"category\":category_list, \"label\":label_list, \"model\":models_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>accessory</td>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>bottom</td>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category</td>\n",
       "      <td>one piece</td>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>top</td>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>shoe</td>\n",
       "      <td>&lt;keras.engine.sequential.Sequential object at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category      label                                              model\n",
       "0  category  accessory  <keras.engine.sequential.Sequential object at ...\n",
       "1  category     bottom  <keras.engine.sequential.Sequential object at ...\n",
       "2  category  one piece  <keras.engine.sequential.Sequential object at ...\n",
       "3  category        top  <keras.engine.sequential.Sequential object at ...\n",
       "4  category       shoe  <keras.engine.sequential.Sequential object at ..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all observations\n",
    "mod_vec.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(test_df2):\n",
    "    '''\n",
    "    This function returns the probabilities of each label with the best combination of vectorizer and model \n",
    "    we got from the our analyses\n",
    "    '''\n",
    "\n",
    "    category_list = []\n",
    "    label_list = []\n",
    "    vectorizer_list = []\n",
    "    pred_val_list = []\n",
    "\n",
    "    i = 'category'\n",
    "    df = df_category.copy()\n",
    "    \n",
    "    labels = list(df.iloc[:,1:-2].columns)\n",
    "\n",
    "    y_test = test_df2['testdoc'].copy()\n",
    "\n",
    "    for j in tqdm_notebook(labels):\n",
    "\n",
    "        # keras tokenizer\n",
    "        tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "        tokenizer.fit_on_texts(df['combined'])\n",
    "\n",
    "        max_length = get_max_token_length_per_doc(df['combined'])\n",
    "\n",
    "        # integer encode the training data\n",
    "        encoded_docs = integer_encode_documents(y_test, tokenizer)\n",
    "        # pad the documents\n",
    "        padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "        model = mod_vec.loc[(mod_vec.category==i)&(mod_vec.label==j),'model'].values[0]\n",
    "\n",
    "        predi = model.predict(padded_docs)[0]\n",
    "        y_pred = predi[0]\n",
    "\n",
    "        category_list.append(i)\n",
    "        label_list.append(j)\n",
    "        pred_val_list.append(y_pred)\n",
    "\n",
    "    pred_labels = pd.DataFrame({\"category\":category_list, \"label\":label_list, \"pred_val\":pred_val_list})\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_labels(df_pred_labels):\n",
    "    '''\n",
    "    This function returns the label with highest prediction value\n",
    "    '''\n",
    "    pred_label_sel = df_pred_labels[df_pred_labels['pred_val']>0.5].copy()\n",
    "    if len(pred_label_sel)==0:\n",
    "        label = ''\n",
    "        return label\n",
    "    pred_label_sel = pred_label_sel.sort_values('pred_val', ascending=False)\n",
    "    pred_label_sel = pred_label_sel.reset_index()\n",
    "    label = pred_label_sel['label'].iloc[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_doc_clean(test_doc):\n",
    "    '''\n",
    "    returns a cleaned test document\n",
    "    '''\n",
    "    # cleaning the test document\n",
    "    test_doc['testdoc'] = test_doc['testdoc'].astype(str).apply(clean_punct)\n",
    "\n",
    "    test_doc['testdoc'] = list(\n",
    "        map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), list(test_doc['testdoc'])))\n",
    "\n",
    "    test_doc['testdoc'] = lemm(test_doc['testdoc'])\n",
    "    \n",
    "    return test_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_match_productID(prod_to_match, prod_df):\n",
    "    '''\n",
    "    This function checks if the entered product ID is already present in our database, \n",
    "    else returns top 5 productIDs closest to the entered product ID using fuzzy library\n",
    "    Input:\n",
    "    - prod_to_match: productID to match\n",
    "    - prod_df: dataframe containing unique products\n",
    "    Output:\n",
    "    - prints string based on match success\n",
    "    - returns a flag to indicate match was successfully found or not\n",
    "    '''\n",
    "    prod_to_match = productID\n",
    "    bests = process.extractBests(prod_to_match, list(prod_df.product_id.unique()), scorer=fuzz.ratio)\n",
    "    if bests[0][1] == 100:\n",
    "        print(f'Product with matching ID found!')\n",
    "        flag = 1\n",
    "        return flag\n",
    "    else:\n",
    "        print(f'We were not able to find the product you were looking for. However, we suggest the following product IDs:')\n",
    "        for i in range(len(bests)):\n",
    "            print(f'{bests[i][0]}')\n",
    "        flag = 0\n",
    "        return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_retproddet(flag, prod_df, prod_to_match):\n",
    "    '''\n",
    "    This function checks if the product ID is present in the dataframe. If yes, return the outfit combination.\n",
    "    Else, show 5 nearest product IDs\n",
    "    \n",
    "    '''\n",
    "      \n",
    "    if flag == 1:\n",
    "        \n",
    "        match_df = prod_df.loc[prod_df['product_id']==prod_to_match].reset_index()\n",
    "        \n",
    "        if len(match_df)==0:\n",
    "            \"Unfortunately, we do not have any outfit recommendations for this product. We apologize for the inconvenience.\"\n",
    "        \n",
    "        for i in list(match_df.outfit_id.unique()):\n",
    "            outfit_rec_df = prod_df.loc[prod_df['outfit_id']==i].reset_index()\n",
    "            #print(outfit_rec_df)\n",
    "            break\n",
    "        \n",
    "        outfit_rec_df = outfit_rec_df.sort_values('outfit_item_type')\n",
    "        \n",
    "        print(\"We would like to recommend the following outfit combination:\")\n",
    "        \n",
    "        for i in range(len(outfit_rec_df)):\n",
    "            outfit_item_type_temp = outfit_rec_df.loc[i,'outfit_item_type'] \n",
    "            product_full_name_temp = outfit_rec_df.loc[i,'product_full_name']\n",
    "            product_id_temp = outfit_rec_df.loc[i,'product_id'] \n",
    "            print(f'{outfit_item_type_temp}: {product_full_name_temp} ({product_id_temp})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the below cell if you have the product ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a product ID:01DMBRYVA2ZFDYRYY5TRQZJTBD\n",
      "Product with matching ID found!\n",
      "We would like to recommend the following outfit combination:\n",
      "bottom: Slim Knit Skirt (01DMBRYVA2P5H24WK0HTK4R0A1)\n",
      "top: Rib Mock Neck Tank (01DMBRYVA2PEPWFTT7RMP5AA1T)\n",
      "accessory: medium margaux leather satchel (01DMBRYVA2S5T9W793F4CY41HE)\n",
      "shoe: Penelope Mid Cap Toe Pump (01DMBRYVA2ZFDYRYY5TRQZJTBD)\n"
     ]
    }
   ],
   "source": [
    "productID = input(\"Please enter a product ID:\")\n",
    "prod_to_match = productID\n",
    "\n",
    "# store the outfits_df in a dataframe\n",
    "prod_df = outfits_df.copy()\n",
    "\n",
    "# return 1 if there is a matching product ID else recommend five closes product IDs\n",
    "flag = step1_match_productID(prod_to_match, prod_df)\n",
    "\n",
    "# get the recommended outfit\n",
    "step2_retproddet(flag, prod_df, prod_to_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(test_brand, test_description, test_brand_category, test_details):\n",
    "    '''\n",
    "    This function returns the best predicted label, combined and cleans the given inputs\n",
    "    '''\n",
    "    # combine the inputs into one string\n",
    "    test_doc = test_brand +\" \" + test_description + \" \" + test_brand_category +\\\n",
    "            \" \" + test_details\n",
    "    \n",
    "    # save it in a dataframe to ease further processes\n",
    "    test_list = ['temp']\n",
    "    test_list[0] = test_doc\n",
    "    test_df2 = pd.DataFrame(data = test_list, columns = [\"testdoc\"])\n",
    "    \n",
    "    # cleaning the document\n",
    "    test_df2 = test_doc_clean(test_df2)\n",
    "    \n",
    "    # getting the label predicted\n",
    "    pred_label = predicted_labels(test_df2)\n",
    "    \n",
    "    # getting the label with highest prediction value\n",
    "    label = best_labels(pred_label)\n",
    "    #print(label)\n",
    "    return label, test_df2.iloc[0].values[0]\n",
    "\n",
    "def subset_df(label, df_category):\n",
    "    '''\n",
    "    This function looks at the subset of labels if there is a prediction of the label\n",
    "    '''\n",
    "    \n",
    "    # use the whole dataframe if no label predicted\n",
    "    if label == '':\n",
    "        sub_df = df_category.copy()\n",
    "        #print(sub_df.head(5))\n",
    "        return df_category\n",
    "    \n",
    "    # filter on the required label if a label is predicted\n",
    "    else:\n",
    "        sub_df = df_category[df_category[label]>0].reset_index()\n",
    "        #print(sub_df.head(5))\n",
    "        return sub_df\n",
    "    \n",
    "def prod_ID(sub_df, test_doc):\n",
    "    '''\n",
    "    This function applies cosine similarity after using nlp word2vec model and returns the product ID with the highest similarity\n",
    "    '''\n",
    "    \n",
    "    # calculate similarity score\n",
    "    for i in range(len(sub_df)):\n",
    "        orig = nlp(sub_df.loc[i,'combined'])\n",
    "        test = nlp(test_doc)\n",
    "        sub_df.loc[i,'Score'] =test.similarity(orig)\n",
    "    \n",
    "    # sort by score and get the product ID with the highest value\n",
    "    sub_df = sub_df.sort_values('Score', ascending = False).reset_index()\n",
    "    #print(sub_df)\n",
    "    product_ID = sub_df['product_id'].iloc[0]\n",
    "    \n",
    "    return product_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the following parameters:\n",
      "Brand:Sexy silky, a-line mini skirt zipper Benson skirt\n",
      "Brand Category:\n",
      "Details:\n",
      "Description:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8967aad7c6154ec08680c5cb9ef56233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Product ID: 01DPKMGJ33SDFXM7XHGPQJWQ12\n",
      "Product with matching ID found!\n",
      "We would like to recommend the following outfit combination:\n",
      "shoe: Pointed-toe flats in suede (01DPCRZWX4S2Z8Q5HYDFM4HNEG)\n",
      "top: Ashlynn Blouse (01DPET2NWSA221STZF740BZ9SW)\n",
      "bottom: Benson Skirt (01DPKMGJ33SDFXM7XHGPQJWQ12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Please enter the following parameters:\")\n",
    "test_brand = input(\"Brand:\")\n",
    "test_brand_category = input(\"Brand Category:\")\n",
    "test_details = input(\"Details:\")\n",
    "test_description = input(\"Description:\")\n",
    "\n",
    "# Printing the output\n",
    "\n",
    "# get the predicted label and cleaned, combined test document\n",
    "label, test_doc = get_label(test_brand, test_description, test_brand_category, test_details)\n",
    "\n",
    "# get a subset of category dataframe if there is a predicted label\n",
    "sub_df = subset_df(label, df_category)\n",
    "\n",
    "# get the product ID with the highest similarity to given input\n",
    "prod_to_match = prod_ID(sub_df, test_doc)\n",
    "print(f'Recommended Product ID: {prod_to_match}')\n",
    "\n",
    "# Return the matching outfit\n",
    "prod_df = outfits_df.copy()\n",
    "\n",
    "# return 1 if there is a matching product ID else recommend five closes product IDs\n",
    "flag = step1_match_productID(prod_to_match, prod_df)\n",
    "\n",
    "# get the recommended outfit\n",
    "step2_retproddet(flag, prod_df, prod_to_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
